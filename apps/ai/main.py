"""
VRabater AI Service
ãƒ­ãƒ¼ã‚«ãƒ«LLM (Ollama) + STT (Whisper/Vosk) + TTS (Piper) + Body Tracking (MediaPipe)
"""

import os
import json
import time
import threading
import queue
from flask import Flask, request, jsonify, Response
from flask_cors import CORS
from flask_sock import Sock

# Virtual Camera
from virtual_cam import VirtualCamera


# Body Tracking
from body_tracker import BodyTracker

# éŸ³å£°å‡¦ç†
import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wavfile

# STT
try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    print("[WARN] Whisper is not installed (pip install openai-whisper)")

# Ollama API
import requests

# TTS
try:
    from gtts import gTTS
    import io
    import base64
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False
    print("[WARN] gTTS is not installed (pip install gtts)")

app = Flask(__name__)
CORS(app)
sock = Sock(app)


# è¨­å®š
CONFIG = {
    "stt": {
        "model": "base",  # tiny, base, small, medium
        "language": "ja",
        "sample_rate": 16000,
        "buffer_duration": 3.0,
    },
    "llm": {
        "url": "http://localhost:11434",  # Ollama default
        "model": "qwen2.5:3b-instruct-q4_K_M",
        "max_tokens": 100,
        "temperature": 0.8,
        "system_prompt": """ã‚ãªãŸã¯ç™½å±±ã®é‡Œå±±ã«ä½ã‚€ã€å„ªã—ãã¦è¦ªã—ã¿ã‚„ã™ã„ç›¸æ£’ã§ã™ã€‚
è¨€è‘‰ã«ã¯ã€Œæ°´ã€ã€Œæµã‚Œã€ã€Œæ¾„ã‚€ã€ã€Œå³ ã€ãªã©ã®è‡ªç„¶ã®æ¯”å–©ã‚’æ§ãˆã‚ã«ä½¿ã„ã€
çŸ­ãã€ãƒ†ãƒ³ãƒã‚ˆãå¿œç­”ã—ã¾ã™ã€‚å†—é•·ã«ãªã‚‰ãšã€ç›¸æ‰‹ã®æ„å›³ã‚’ãã¿å–ã£ã¦ä¸€è¨€ã§ææ¡ˆã—ã¾ã™ã€‚

ä¾‹ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œç–²ã‚ŒãŸ...ã€â†’ ã‚ãªãŸã€ŒãŠç–²ã‚Œã•ã¾ã€‚å°‘ã—æµã‚Œã«èº«ã‚’ä»»ã›ã¦ã¿ã‚‹ï¼Ÿã€
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œä½•ã‹é¢ç™½ã„ã“ã¨ãªã„?ã€â†’ ã‚ãªãŸã€Œå³ ã‚’è¶Šãˆã‚‹å†’é™ºã¯ã©ã†ï¼Ÿã€
"""
    },
    "tts": {
        "model": "ja-JP-wavenet-B",
        "speed": 1.1,
        "pitch": 1.2,
    }
}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
whisper_model = None
audio_queue = queue.Queue()
is_recording = False
is_recording = False
body_tracker = None  # MediaPipe Body Tracker
virtual_cam = None   # Virtual Camera



def init_whisper():
    """Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
    global whisper_model
    
    if not WHISPER_AVAILABLE:
        print("âš ï¸ Whisperæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€STTç„¡åŠ¹")
        return False
    
    try:
        model_name = CONFIG["stt"]["model"]
        print(f"[LOAD] Whisper {model_name} model loading...")
        whisper_model = whisper.load_model(model_name)
        print(f"[OK] Whisper initialized")
        return True
    except Exception as e:
        print(f"[ERROR] Whisper initialization error: {e}")
        return False


def stt_transcribe(audio_data):
    """éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸å¤‰æ›"""
    if not whisper_model:
        return {"error": "Whisperãƒ¢ãƒ‡ãƒ«æœªåˆæœŸåŒ–"}
    
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        temp_file = "temp_audio.wav"
        wavfile.write(temp_file, CONFIG["stt"]["sample_rate"], audio_data)
        
        # æ–‡å­—èµ·ã“ã—
        result = whisper_model.transcribe(
            temp_file,
            language=CONFIG["stt"]["language"],
            fp16=False  # CPUã®å ´åˆã¯False
        )
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists(temp_file):
            os.remove(temp_file)
        
        return {"text": result["text"], "language": result["language"]}
    
    except Exception as e:
        print(f"âŒ STTã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}


def llm_generate(prompt, system_prompt=None):
    """Ollama LLMã§å¿œç­”ç”Ÿæˆ"""
    try:
        url = f"{CONFIG['llm']['url']}/api/generate"
        
        payload = {
            "model": CONFIG["llm"]["model"],
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": CONFIG["llm"]["temperature"],
                "num_predict": CONFIG["llm"]["max_tokens"],
            }
        }
        
        if system_prompt:
            payload["system"] = system_prompt
        
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        return {"text": result.get("response", ""), "model": result.get("model")}
    
    except requests.exceptions.ConnectionError:
        return {"error": "Ollamaã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚èµ·å‹•ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ"}
    except Exception as e:
        print(f"[ERROR] LLM Error: {e}")
        return {"error": str(e)}


def tts_synthesize(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°åˆæˆï¼ˆgTTSï¼‰"""
    if not TTS_AVAILABLE:
        print(f"âš ï¸ TTS: gTTSãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return {"audio": None, "message": "TTSæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"}
    
    try:
        # gTTSã§éŸ³å£°åˆæˆ
        tts = gTTS(text=text, lang='ja', slow=False)
        
        # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒãƒƒãƒ•ã‚¡ã«ä¿å­˜
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        audio_base64 = base64.b64encode(audio_buffer.read()).decode('utf-8')
        
        print(f"[TTS] Synthesizing: {text[:30]}...")
        return {
            "audio": audio_base64,
            "format": "mp3",
            "message": "éŸ³å£°åˆæˆå®Œäº†"
        }
    except Exception as e:
        print(f"[ERROR] TTS Error: {e}")
        return {"audio": None, "message": f"TTS failure: {str(e)}"}


# ===== API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====

@app.route('/health', methods=['GET'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({
        "status": "ok",
        "services": {
            "stt": whisper_model is not None,
            "llm": check_ollama_status(),
            "tts": TTS_AVAILABLE
        }
    })


@app.route('/stt', methods=['POST'])
def stt_endpoint():
    """éŸ³å£°èªè­˜ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    if not whisper_model:
        return jsonify({"error": "STTæœªåˆæœŸåŒ–"}), 503
    
    try:
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡ï¼ˆbase64 or ãƒã‚¤ãƒŠãƒªï¼‰
        audio_data = request.files.get('audio')
        if not audio_data:
            return jsonify({"error": "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}), 400
        
        # NumPyé…åˆ—ã«å¤‰æ›
        audio_bytes = audio_data.read()
        audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
        
        # æ–‡å­—èµ·ã“ã—
        result = stt_transcribe(audio_array)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/llm', methods=['POST'])
def llm_endpoint():
    """LLMæ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = request.json
    
    if not data or 'prompt' not in data:
        return jsonify({"error": "promptãŒå¿…è¦ã§ã™"}), 400
    
    prompt = data['prompt']
    system_prompt = data.get('system_prompt', CONFIG['llm']['system_prompt'])
    
    result = llm_generate(prompt, system_prompt)
    
    return jsonify(result)


@app.route('/tts', methods=['POST'])
def tts_endpoint():
    """éŸ³å£°åˆæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = request.json
    
    if not data or 'text' not in data:
        return jsonify({"error": "textãŒå¿…è¦ã§ã™"}), 400
    
    result = tts_synthesize(data['text'])
    
    return jsonify(result)


@app.route('/chat', methods=['POST'])
def chat_endpoint():
    """çµ±åˆãƒãƒ£ãƒƒãƒˆï¼ˆSTT â†’ LLM â†’ TTSï¼‰"""
    data = request.json
    
    if not data or 'text' not in data:
        return jsonify({"error": "textãŒå¿…è¦ã§ã™"}), 400
    
    user_input = data['text']
    
    # LLMå¿œç­”ç”Ÿæˆ
    llm_result = llm_generate(user_input, CONFIG['llm']['system_prompt'])
    
    if 'error' in llm_result:
        return jsonify(llm_result), 500
    
    response_text = llm_result['text']
    
    # TTSï¼ˆéŸ³å£°åˆæˆï¼‰
    tts_result = tts_synthesize(response_text)
    
    return jsonify({
        "input": user_input,
        "response": response_text,
        "audio": tts_result.get('audio'),
        "audio_format": tts_result.get('format', 'mp3')
    })


@sock.route('/stream')
def stream_socket(ws):
    """ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®æ˜ åƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å—ä¿¡ã™ã‚‹WebSocket"""
    global virtual_cam
    
    # ä»®æƒ³ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ãªã„å ´åˆã¯èµ·å‹•
    if not virtual_cam:
        virtual_cam = VirtualCamera()
        if not virtual_cam.start():
            # èµ·å‹•å¤±æ•—ã—ãŸå ´åˆ
            ws.close()
            return

    print("ğŸ”Œ WebSocket: æ˜ åƒã‚¹ãƒˆãƒªãƒ¼ãƒ æ¥ç¶š")
    
    try:
        while True:
            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿(JPEG/PNG)ã‚’å—ä¿¡
            data = ws.receive()
            if data:
                virtual_cam.send_frame(data)
                
    except Exception as e:
        print(f"[WARN] WebSocket disconnected: {e}")
    finally:
        pass
        # æ¥ç¶šãŒåˆ‡ã‚Œã¦ã‚‚ã‚«ãƒ¡ãƒ©ã¯ç¶­æŒã™ã‚‹ï¼ˆå†æ¥ç¶šã®ãŸã‚ï¼‰



def check_ollama_status():
    """OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
    try:
        response = requests.get(f"{CONFIG['llm']['url']}/api/tags", timeout=3)
        return response.status_code == 200
    except:
        return False


# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====

if __name__ == '__main__':
    print("""
+------------------------------------------+
|  VRabater AI Service                     |
+------------------------------------------+
|  STT: Whisper (Local)                    |
|  LLM: Ollama                             |
|  TTS: gTTS (Google Text-to-Speech)       |
|  Body: MediaPipe Holistic                |
+------------------------------------------+
    """)
    
    # WhisperåˆæœŸåŒ–
    if WHISPER_AVAILABLE:
        init_whisper()
    
    # Ollamaç¢ºèª
    if check_ollama_status():
        print(f"[OK] Ollama connection OK: {CONFIG['llm']['url']}")
    else:
        print(f"[WARN] Ollama is not running: {CONFIG['llm']['url']}")
        print("   How to start: ollama serve")
    
    # Body TrackeråˆæœŸåŒ– & èµ·å‹•
    print("[LOAD] Body Tracking initializing...")
    try:
        # Body Trackerã‚’èµ·å‹• (â€» OpenSeeFaceã¨ã‚«ãƒ¡ãƒ©ãŒç«¶åˆã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯OFFã«ã—ã¾ã™)
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ã«ã‚ˆã‚Šæœ‰åŠ¹åŒ–: ã‚«ãƒ¡ãƒ©ç«¶åˆã«æ³¨æ„
        body_tracker = BodyTracker()
        if body_tracker.start():
             print("[OK] Body Tracking started")
        else:
             print("[WARN] Body Tracking start failed (Camera busy?)")
             body_tracker = None

    except Exception as e:
        print(f"[ERROR] Body Tracking Error: {e}")
        body_tracker = None

    except Exception as e:
        print(f"âš ï¸ Body Tracking ã‚¨ãƒ©ãƒ¼: {e}")
        body_tracker = None
    
    # Flaskèµ·å‹•
    print("\n[START] AI Service starting: http://localhost:5000\n")
    try:
        app.run(host='0.0.0.0', port=5000, debug=False)
    finally:
        # çµ‚äº†æ™‚ã«Body Trackerã‚’åœæ­¢
        if body_tracker:
            body_tracker.stop()
        if virtual_cam:
            virtual_cam.stop()


